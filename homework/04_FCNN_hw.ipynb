{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Домашняя работа. Нейросеть на numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В этой домашней работе вы реализуете свою нейросеть, при этом не используя специальных фреймворков для прототипирования и обучения нейросетей (PyTorch или TensorFlow). Нам потребуется только numpy и знания, которые вы успели приобрести с течением курса.\n",
    "\n",
    "\n",
    "В данной тетрадке уже реализован базовый функционал. Осталось реализовать \"вычислительную часть\". Дополните предложенные функции и обучите свою нейросеть. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Импортируем нужные библиотеки и вспомогательные тесты."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tests.hw7 import test_linear_forward, test_linear_backward, test_svm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Подготовка данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузим набор данных с рукописными цифрами. Воспользуемся функцией `load_digits` из библиотеки `sklearn`. 1500 картинок оставим для обучения нейросети, остальные 297 для тестирования. Каждая кратинка имеет размер 8х8, то есть содержит в себе 64 пикселя."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "\n",
    "X, Y = load_digits(return_X_y=True)\n",
    "# 1500 картинок с цифрами отложим на обучение\n",
    "X_train = X[:1500] # X хранит векторы с пикселями\n",
    "y_train = Y[:1500] # Y хранит \"ответы\"\n",
    "\n",
    "X_test = X[1500:]\n",
    "y_test = Y[1500:]\n",
    "\n",
    "print(X_train.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Так выглядит вектор ответов для первых 10-ти изображений"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим как выглядят картинки с данными:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(5,5, figsize=(12,12))\n",
    "axes = np.ravel(axes)\n",
    "for i in range(len(axes)):\n",
    "    axes[i].imshow(X_train[i].reshape(8, 8))\n",
    "    axes[i].set_title(f'target: {y_train[i]}')\n",
    "    axes[i].axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "### Программирование линейного слоя (forward pass, backward pass)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Дополните функции `linear_forward` и `linear_backward` требуемым функционалом"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def linear_forward(x, w, b):\n",
    "    \"\"\"\n",
    "    Функция, которая реализует функционал линейного слоя нейросети.\n",
    "    \n",
    "    Входные параметры:\n",
    "    ----------------\n",
    "    - x: матрица входных данных размером (B, I)\n",
    "        B - размер батча (кол-во картинок),\n",
    "        I - количество пикселей в каждой картинке\n",
    "        \n",
    "    - w: матрица весов размером (I, C)\n",
    "        I - количество пикселей в каждой картинке\n",
    "        C - количество классов в задаче классификации\n",
    "        \n",
    "    - b: вектор смещения длинной C\n",
    "        C - количество классов в задаче классификации\n",
    "    \n",
    "    Выходные параметры:\n",
    "    ----------------\n",
    "    - out: матрица размером (B, C)\n",
    "    - cache: список с входными данными (требуется для вычисления производных)\n",
    "    \"\"\"\n",
    "    out = None\n",
    "    cache = [x, w, b] # сохраняем входные данные для дальнейшего вычисления градиента\n",
    "    \n",
    "    # Ниже реализуйте код, который вычисляет результат линейного слоя xW + b.\n",
    "    # Результат поместите в переменную out.\n",
    "    \n",
    "    # Ваш код здесь\n",
    "    \n",
    "    return out, cache\n",
    "\n",
    "def linear_backward(ds, cache):\n",
    "    \"\"\"\n",
    "    Функция, вычисляющая градиент для матрицы W и вектора b.\n",
    "    \n",
    "    Входные параметры:\n",
    "    ----------------\n",
    "    - ds: градиент для веткора scores размером (B, C)\n",
    "        B - размер батча (кол-во картинок)\n",
    "        C - количество классов в задаче классификации\n",
    "        \n",
    "    - cache: \n",
    "        список с входными данными, которые использовались \n",
    "        при вычислении forward_pass\n",
    "    \n",
    "    Выходные параметры:\n",
    "    ----------------\n",
    "    - dw, db - градиенты для матрицы W и вектора b\n",
    "    \"\"\"\n",
    "    \n",
    "    x = cache[0]\n",
    "    w = cache[1]\n",
    "    b = cache[2]\n",
    "    \n",
    "    dw = None\n",
    "    \n",
    "    # Для вычисления градиента по b, нам надо покомпонентно суммировать scores\n",
    "    # для всех картинок из батча.\n",
    "    #\n",
    "    # Представим, будто мы пропустили 5 картинок и в каждой по 3 пикселя, \n",
    "    # всего может быть 2 класса. Тогда scores будет матрицей размером (5,2).\n",
    "    # Для каждой компоненты вектора b, производная будет равна единице, умноженной\n",
    "    # на соответствующую комопненту градиета ds. Чтобы вычислить итоговый градиент\n",
    "    # (для всех 5-ти картинок сразу) надо сложить по столбцам матрицу scores. \n",
    "    db = ds.sum(0) \n",
    "    \n",
    "    # Ниже вычислите производную для матрицы W\n",
    "    \n",
    "    # Ваш код здесь\n",
    "    \n",
    "    return (dw, db)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверьте правильность реализации с помощью вспомогательных тестов. Или же протестируйте самостоятельно (очень полезное упражнение)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_linear_forward(linear_forward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_linear_backward(linear_forward, linear_backward)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM-loss\n",
    "\n",
    "Реализуйте вычисление SVM-loss и вычисление градиента вектора scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svm_loss(scores, true_labels):\n",
    "    \"\"\"\n",
    "    Функция, вычисляющая значение ошибки SVM-loss.\n",
    "    \n",
    "    Входные параметры:\n",
    "    ----------------\n",
    "    - scores: вектор размером (B, C)\n",
    "        B - размер батча (кол-во картинок)\n",
    "        C - количество классов в задаче классификации\n",
    "        \n",
    "    - true_labels: список с метками классов размера B\n",
    "        B - размер батча (кол-во картинок)\n",
    "        \n",
    "    Выходные параметры:\n",
    "    ----------------\n",
    "    - loss: численное значение ошибки\n",
    "    - ds: градиент вектора scores\n",
    "    \"\"\"\n",
    "    loss = None\n",
    "    ds = None\n",
    "    \n",
    "    # Ниже вычислите значение ошибки при данных scores и true_labels.\n",
    "    # Тут же вычислим значение градиента вектора scores (ds).\n",
    "\n",
    "    # Ваш код здесь\n",
    "    \n",
    "    return loss, ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверьте правильность реализации с помощью вспомогательного теста. Или же протестируйте самостоятельно."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_svm(svm_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обучаем нейросеть\n",
    "\n",
    "Теперь дополните функцию train, которая будет тренировать вашу нейросеть."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(x, y, batch_size=256, epochs=30, lr=5e-3):\n",
    "    \"\"\"\n",
    "    Функция, которая обучает нейросеть указанное кол-во эпох и возвращает подобранные W и b.\n",
    "    \n",
    "    Входные параметры:\n",
    "    ----------------\n",
    "    - x: матрица тренировочных данных размером (N, I)\n",
    "        N - кол-во картинок\n",
    "        I - количество пикселей в каждой картинке\n",
    "        \n",
    "    - y: вектор ответов размером N\n",
    "        N - кол-во картинок\n",
    "    \n",
    "    - batch_size: \n",
    "        размер батча, то есть кол-во картинок, которое будем пропускать через нейросеть за раз\n",
    "        \n",
    "    - epochs:\n",
    "        кол-во эпох обучения (сколько раз нейросеть увидит кажду картинку)\n",
    "        \n",
    "    - lr:\n",
    "        шаг обучения (learning rate) - коэффициент перед градиентом\n",
    "        \n",
    "    \n",
    "        \n",
    "    Выходные параметры:\n",
    "    ----------------\n",
    "    - W: обученная матрица W\n",
    "    - b: обученный вектор b\n",
    "    \n",
    "    \"\"\"\n",
    "    N = len(x)\n",
    "    \n",
    "    # определяем веса нейросети случайным образом\n",
    "    W = np.random.normal(size=(64, 10))\n",
    "    b = np.ones(10)\n",
    "    \n",
    "    for e in range(1, epochs):\n",
    "        epoch_loss = []\n",
    "        for idx in range(0, N, batch_size):\n",
    "            # извлекаем батч данных, который будем пропускать через нейросеть\n",
    "            x_batch = x[idx : min(idx+batch_size, N)]\n",
    "            y_batch = y[idx : min(idx+batch_size, N)]\n",
    "\n",
    "            # пропускаем данные через линейный слой (forward pass)\n",
    "            scores, cache = linear_forward(x_batch, W, b)\n",
    "            \n",
    "            # вычисляем значение ошибки\n",
    "            loss, ds = svm_loss(scores, y_batch)\n",
    "            epoch_loss.append(loss)\n",
    "\n",
    "            # вычисляем градиенты (backward pass0\n",
    "            dW, db = linear_backward(ds, cache)\n",
    "\n",
    "            ############################################################\n",
    "            ############################################################\n",
    "            ##                                                        ##\n",
    "            ## Далее обновите веса вашей матрицы W и вектора b. Не забудьте ##\n",
    "            ## умножить значения градиентов на lr - learning rate.        ##\n",
    "            ##                                                        ##\n",
    "            ############################################################\n",
    "            ############################################################\n",
    "            \n",
    "            # Ваш код здесь\n",
    "\n",
    "        print(f'epoch {e} | SVM-loss = {np.mean(epoch_loss)}')\n",
    "        \n",
    "    return W, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "W, b = train(X_train, y_train, epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обучили, а теперь тестируем!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Определим функцию, которая будет вычислять предсказание обученной нейросети"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(x, W, b, batch_size=256):\n",
    "    \"\"\"\n",
    "    Функция, которая вычисляет предсказание обученной нейросети.\n",
    "    \"\"\"\n",
    "    N = len(x)\n",
    "    pred = []\n",
    "    for idx in range(0, N, batch_size):\n",
    "        x_batch = x[idx : min(idx+batch_size, N)]\n",
    "\n",
    "        out, _ = linear_forward(x_batch, W, b)\n",
    "\n",
    "        pred.append(np.argmax(out, 1))\n",
    "    return np.concatenate(pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вычислим точность обученной вами модели в процентах. При успешной реализации всех функций точность модели должна быть около 90%. То есть в 9 случаях из 10 модель правильно угадывает цифру! Очень неплохо :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = predict(X_test, W, b)\n",
    "\n",
    "(y_pred == y_test).mean() * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь полюбуемся на результат: посмотрим на картинки и предсказания модели "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_idx = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(5,5, figsize=(12,12))\n",
    "\n",
    "axes = np.ravel(axes)\n",
    "\n",
    "for i in range(len(axes)):\n",
    "    p = y_pred[i]\n",
    "    t = y_test[i]\n",
    "    c = 'green' if p == t else 'red'\n",
    "    axes[i].imshow(X_test[i + start_idx].reshape(8, 8))\n",
    "    axes[i].set_title(f'{p} | Правда: {t}', color=c)\n",
    "    axes[i].axis('off')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
